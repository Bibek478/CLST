{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T11:22:23.968561Z",
     "iopub.status.busy": "2025-07-20T11:22:23.967840Z",
     "iopub.status.idle": "2025-07-20T12:24:10.243709Z",
     "shell.execute_reply": "2025-07-20T12:24:10.242947Z",
     "shell.execute_reply.started": "2025-07-20T11:22:23.968539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started—see epoch markers below.\n",
      "\n",
      ">>> Epoch 1/30\n",
      "........\n",
      "Epoch 1 done in 3.2m | TrainLoss 7.781 | ValLoss 7.229 | BLEU 0.37 | TF 1.00 | LR 0.00005\n",
      "  → New best BLEU saved\n",
      "  → New best ValLoss saved\n",
      "\n",
      ">>> Epoch 2/30\n",
      "........\n",
      "Epoch 2 done in 3.3m | TrainLoss 6.977 | ValLoss 7.437 | BLEU 0.61 | TF 1.00 | LR 0.00014\n",
      "  → New best BLEU saved\n",
      "\n",
      ">>> Epoch 3/30\n",
      "........\n",
      "Epoch 3 done in 3.3m | TrainLoss 6.545 | ValLoss 7.891 | BLEU 0.28 | TF 1.00 | LR 0.00026\n",
      "  No improvement for 1/10 epochs\n",
      "\n",
      ">>> Epoch 4/30\n",
      "........\n",
      "Epoch 4 done in 3.3m | TrainLoss 5.923 | ValLoss 8.068 | BLEU 0.44 | TF 1.00 | LR 0.00038\n",
      "  No improvement for 2/10 epochs\n",
      "\n",
      ">>> Epoch 5/30\n",
      "........\n",
      "Epoch 5 done in 3.2m | TrainLoss 5.258 | ValLoss 8.356 | BLEU 4.05 | TF 1.00 | LR 0.00047\n",
      "  → New best BLEU saved\n",
      "\n",
      ">>> Epoch 6/30\n",
      "........\n",
      "Epoch 6 done in 3.2m | TrainLoss 4.594 | ValLoss 8.182 | BLEU 1.03 | TF 0.96 | LR 0.00050\n",
      "  No improvement for 1/10 epochs\n",
      "\n",
      ">>> Epoch 7/30\n",
      "........\n",
      "Epoch 7 done in 3.3m | TrainLoss 3.937 | ValLoss 8.221 | BLEU 2.11 | TF 0.92 | LR 0.00050\n",
      "  No improvement for 2/10 epochs\n",
      "\n",
      ">>> Epoch 8/30\n",
      "........\n",
      "Epoch 8 done in 3.3m | TrainLoss 3.479 | ValLoss 8.287 | BLEU 0.90 | TF 0.88 | LR 0.00049\n",
      "  No improvement for 3/10 epochs\n",
      "\n",
      ">>> Epoch 9/30\n",
      "........\n",
      "Epoch 9 done in 3.3m | TrainLoss 3.204 | ValLoss 8.334 | BLEU 5.23 | TF 0.84 | LR 0.00048\n",
      "  → New best BLEU saved\n",
      "\n",
      ">>> Epoch 10/30\n",
      "........\n",
      "Epoch 10 done in 3.2m | TrainLoss 3.005 | ValLoss 8.417 | BLEU 1.08 | TF 0.80 | LR 0.00047\n",
      "  No improvement for 1/10 epochs\n",
      "\n",
      ">>> Epoch 11/30\n",
      "........\n",
      "Epoch 11 done in 3.3m | TrainLoss 2.836 | ValLoss 8.372 | BLEU 1.08 | TF 0.76 | LR 0.00045\n",
      "  No improvement for 2/10 epochs\n",
      "\n",
      ">>> Epoch 12/30\n",
      "........\n",
      "Epoch 12 done in 3.2m | TrainLoss 2.698 | ValLoss 8.371 | BLEU 1.13 | TF 0.72 | LR 0.00043\n",
      "  No improvement for 3/10 epochs\n",
      "\n",
      ">>> Epoch 13/30\n",
      "........\n",
      "Epoch 13 done in 3.2m | TrainLoss 2.554 | ValLoss 8.467 | BLEU 1.92 | TF 0.68 | LR 0.00040\n",
      "  No improvement for 4/10 epochs\n",
      "\n",
      ">>> Epoch 14/30\n",
      "........\n",
      "Epoch 14 done in 3.2m | TrainLoss 2.469 | ValLoss 8.457 | BLEU 0.88 | TF 0.64 | LR 0.00037\n",
      "  No improvement for 5/10 epochs\n",
      "\n",
      ">>> Epoch 15/30\n",
      "........\n",
      "Epoch 15 done in 3.2m | TrainLoss 2.367 | ValLoss 8.431 | BLEU 0.85 | TF 0.60 | LR 0.00035\n",
      "  No improvement for 6/10 epochs\n",
      "\n",
      ">>> Epoch 16/30\n",
      "........\n",
      "Epoch 16 done in 3.2m | TrainLoss 2.232 | ValLoss 8.440 | BLEU 1.79 | TF 0.56 | LR 0.00031\n",
      "  No improvement for 7/10 epochs\n",
      "\n",
      ">>> Epoch 17/30\n",
      "........\n",
      "Epoch 17 done in 3.2m | TrainLoss 2.111 | ValLoss 8.439 | BLEU 1.75 | TF 0.52 | LR 0.00028\n",
      "  No improvement for 8/10 epochs\n",
      "\n",
      ">>> Epoch 18/30\n",
      "........\n",
      "Epoch 18 done in 3.2m | TrainLoss 1.981 | ValLoss 8.450 | BLEU 2.16 | TF 0.48 | LR 0.00025\n",
      "  No improvement for 9/10 epochs\n",
      "\n",
      ">>> Epoch 19/30\n",
      "........\n",
      "Epoch 19 done in 3.2m | TrainLoss 1.835 | ValLoss 8.529 | BLEU 2.19 | TF 0.44 | LR 0.00022\n",
      "  No improvement for 10/10 epochs\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "import time, pandas as pd, numpy as np, random, torch\n",
    "import torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import sentencepiece as spm, nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  1. SETUP \n",
    "nltk.download('punkt', quiet=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed(42)\n",
    "\n",
    "#  2. LOAD & TOKENIZER \n",
    "df = pd.read_csv('/kaggle/input/filtered/Filtered_data.tsv', sep='\\t',\n",
    "                 names=['asm','eng'], on_bad_lines='skip').dropna()\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df  = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "with open('all.txt','w',encoding='utf-8') as f:\n",
    "    for t in pd.concat([train_df['asm'], train_df['eng']]):\n",
    "        f.write(t.lower().strip() + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input=all.txt --model_prefix=spm --vocab_size=16000 '\n",
    "    '--character_coverage=1.0 --model_type=bpe '\n",
    "    '--pad_id=0 --pad_piece=<pad> --bos_id=1 --bos_piece=<s> '\n",
    "    '--eos_id=2 --eos_piece=</s> --unk_id=3 --unk_piece=<unk>'\n",
    ")\n",
    "sp = spm.SentencePieceProcessor(); sp.Load('spm.model')\n",
    "PAD,SOS,EOS,UNK = sp.pad_id(), sp.bos_id(), sp.eos_id(), sp.unk_id()\n",
    "VOCAB_SIZE = sp.GetPieceSize()\n",
    "\n",
    "#  3. DATASET & DATALOADERS \n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, df, max_len=100):\n",
    "        self.src = df['asm'].astype(str).tolist()\n",
    "        self.trg = df['eng'].astype(str).tolist()\n",
    "        self.max = max_len\n",
    "    def __len__(self): return len(self.src)\n",
    "    def __getitem__(self,i):\n",
    "        src_ids = [SOS] + sp.EncodeAsIds(self.src[i].lower())[:self.max-2] + [EOS]\n",
    "        trg_ids = [SOS] + sp.EncodeAsIds(self.trg[i].lower())[:self.max-2] + [EOS]\n",
    "        return torch.LongTensor(src_ids), torch.LongTensor(trg_ids)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs, trgs = zip(*batch)\n",
    "    return (pad_sequence(srcs, batch_first=True, padding_value=PAD),\n",
    "            pad_sequence(trgs, batch_first=True, padding_value=PAD))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(TranslationDataset(train_df), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(TranslationDataset(val_df),   batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(TranslationDataset(test_df),  batch_size=BATCH_SIZE, shuffle=False,collate_fn=collate_fn)\n",
    "\n",
    "#  4. MODEL ARCH \n",
    "EMB_DIM, HID_DIM = 400, 1024\n",
    "ENC_LAYERS, DEC_LAYERS, DROPOUT = 4, 4, 0.1\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vs,ed,hd,nl,drop):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vs,ed,padding_idx=PAD)\n",
    "        self.gru = nn.GRU(ed,hd,nl,bidirectional=True,dropout=drop,batch_first=True)\n",
    "        self.fc  = nn.Linear(hd*2,hd)\n",
    "        self.do  = nn.Dropout(drop)\n",
    "        self.nl,self.hd = nl,hd\n",
    "    def forward(self,src):\n",
    "        emb = self.do(self.embedding(src))\n",
    "        out,h = self.gru(emb)\n",
    "        B = src.size(0)\n",
    "        h = h.view(self.nl,2,B,self.hd)\n",
    "        h_cat = torch.cat([h[:,0],h[:,1]],dim=2)\n",
    "        return out, torch.tanh(self.fc(h_cat))\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,hd):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hd*3,hd)\n",
    "        self.v    = nn.Linear(hd,1,bias=False)\n",
    "    def forward(self,dec_h,enc_o,mask):\n",
    "        B,T,_ = enc_o.size()\n",
    "        dt = dec_h[-1].unsqueeze(1).expand(-1,T,-1)\n",
    "        e  = torch.tanh(self.attn(torch.cat([dt,enc_o],dim=2)))\n",
    "        s  = self.v(e).squeeze(2).masked_fill(mask==0,-1e10)\n",
    "        return torch.softmax(s,dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vs,ed,eh,dh,nl,drop,attn):\n",
    "        super().__init__()\n",
    "        self.emb  = nn.Embedding(vs,ed,padding_idx=PAD)\n",
    "        self.attn = attn\n",
    "        self.gru  = nn.GRU(ed+eh*2,dh,nl,dropout=drop,batch_first=True)\n",
    "        self.fc   = nn.Linear(dh+eh*2+ed,vs)\n",
    "        self.do   = nn.Dropout(drop)\n",
    "    def forward(self,in_tok,h,enc_o,mask):\n",
    "        emb = self.do(self.emb(in_tok).unsqueeze(1))\n",
    "        w   = self.attn(h,enc_o,mask).unsqueeze(1)\n",
    "        ctx = torch.bmm(w,enc_o)\n",
    "        inp = torch.cat([emb,ctx],dim=2)\n",
    "        out,nh = self.gru(inp,h)\n",
    "        o,emb,ctx = out.squeeze(1),emb.squeeze(1),ctx.squeeze(1)\n",
    "        return self.fc(torch.cat([o,ctx,emb],1)), nh\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,e,d):\n",
    "        super().__init__(); self.enc=e; self.dec=d\n",
    "    def forward(self,src,trg,tf):\n",
    "        B,T = trg.size(); V=self.dec.emb.num_embeddings\n",
    "        out = torch.zeros(B,T,V,device=src.device)\n",
    "        enc_o,h = self.enc(src)\n",
    "        mask = (src!=PAD)\n",
    "        inp = trg[:,0]\n",
    "        for t in range(1,T):\n",
    "            pred,h = self.dec(inp,h,enc_o,mask)\n",
    "            out[:,t] = pred\n",
    "            inp = trg[:,t] if random.random()<tf else pred.argmax(1)\n",
    "        return out\n",
    "\n",
    "# share embeddings\n",
    "enc = Encoder(VOCAB_SIZE,EMB_DIM,HID_DIM,ENC_LAYERS,DROPOUT)\n",
    "dec = Decoder(VOCAB_SIZE,EMB_DIM,HID_DIM,HID_DIM,DEC_LAYERS,DROPOUT,Attention(HID_DIM))\n",
    "dec.emb.weight = enc.embedding.weight\n",
    "model = Seq2Seq(enc,dec).to(device)\n",
    "\n",
    "#  5. TRAINING SETUP \n",
    "NUM_EPOCHS, PATIENCE = 30, 10\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD, label_smoothing=0.1)\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "total_steps = NUM_EPOCHS * len(train_loader)\n",
    "scheduler = OneCycleLR(optimizer,\n",
    "    max_lr=5e-4,\n",
    "    total_steps=NUM_EPOCHS * len(train_loader),\n",
    "    pct_start=0.2,\n",
    "    anneal_strategy='cos') \n",
    "smooth = SmoothingFunction().method1\n",
    "\n",
    "#  6. \n",
    "def beam_search(src, k=5, max_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_o,h = model.enc(src)\n",
    "        mask = (src!=PAD)\n",
    "        beams = [([SOS],0.0,h)]\n",
    "        for _ in range(max_len):\n",
    "            nxt=[]\n",
    "            for seq,sc,hh in beams:\n",
    "                if seq[-1]==EOS:\n",
    "                    nxt.append((seq,sc,hh)); continue\n",
    "                inp = torch.tensor([seq[-1]],device=src.device)\n",
    "                out,hh2 = model.dec(inp,hh,enc_o,mask)\n",
    "                lp = torch.log_softmax(out,1).squeeze(0)\n",
    "                v,i = lp.topk(k)\n",
    "                for j in range(k):\n",
    "                    nxt.append((seq+[i[j].item()], sc+v[j].item(), hh2))\n",
    "            beams = sorted(nxt, key=lambda x:-x[1])[:k]\n",
    "            if all(s[-1]==EOS for s,_,_ in beams): break\n",
    "        return beams[0][0][1:-1]\n",
    "\n",
    "def compute_val_loss():\n",
    "    model.eval(); vl=0\n",
    "    with torch.no_grad():\n",
    "        for src,trg in val_loader:\n",
    "            src,trg=src.to(device),trg.to(device)\n",
    "            out = model(src,trg,0.0)\n",
    "            of = out[:,1:,:].reshape(-1,VOCAB_SIZE)\n",
    "            tf = trg[:,1:].reshape(-1)\n",
    "            vl += criterion(of,tf).item()\n",
    "    return vl / len(val_loader)\n",
    "\n",
    "def calc_bleu(quick=True):\n",
    "    refs,hyps=[],[]\n",
    "    model.eval()\n",
    "    max_batches = 2 if quick else 10\n",
    "    samples_per = 3 if quick else 5\n",
    "    with torch.no_grad():\n",
    "        for i,(src,trg) in enumerate(val_loader):\n",
    "            if i>=max_batches: break\n",
    "            src,trg=src.to(device),trg.to(device)\n",
    "            for j in range(min(src.size(0), samples_per)):\n",
    "                ps = beam_search(src[j:j+1],k=5,max_len=trg.size(1))\n",
    "                hyps.append(sp.DecodeIds(ps).split())\n",
    "                r = trg[j].tolist()\n",
    "                if EOS in r: r = r[1:r.index(EOS)]\n",
    "                refs.append([sp.DecodeIds(r).split()])\n",
    "    return corpus_bleu(refs,hyps,smoothing_function=smooth) * 100\n",
    "\n",
    "#  6b. Teacher‑forcing schedule \n",
    "def get_tf_ratio(ep):\n",
    "    if ep <= 5:\n",
    "        return 1.0\n",
    "    return max(0.1, 1.0 - (ep - 5) / (NUM_EPOCHS - 5))\n",
    "\n",
    "#  7. TRAINING LOOP w combined early stop \n",
    "print(\"Training started—see epoch markers below.\")\n",
    "best_bleu = 0.0\n",
    "best_val_loss = float('inf')\n",
    "no_imp = 0\n",
    "\n",
    "for ep in range(1, NUM_EPOCHS + 1):\n",
    "    start = time.time()\n",
    "    print(f\"\\n>>> Epoch {ep}/{NUM_EPOCHS}\", flush=True)\n",
    "\n",
    "    model.train()\n",
    "    tf_ratio = get_tf_ratio(ep)\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for b, (src, trg) in enumerate(train_loader, 1):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(src, trg, tf_ratio)\n",
    "        of = out[:,1:,:].reshape(-1, VOCAB_SIZE)\n",
    "        tf = trg[:,1:].reshape(-1)\n",
    "        loss = criterion(of, tf)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "        if b % 20 == 0:\n",
    "            print(\".\", end=\"\", flush=True)\n",
    "\n",
    "    # --- VALIDATION METRICS ---\n",
    "    val_bleu = calc_bleu(quick=True)\n",
    "    val_loss = compute_val_loss()\n",
    "    epoch_time = (time.time() - start) / 60\n",
    "    avg_train = train_loss / len(train_loader)\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    print(f\"\\nEpoch {ep} done in {epoch_time:.1f}m | \"\n",
    "          f\"TrainLoss {avg_train:.3f} | ValLoss {val_loss:.3f} | \"\n",
    "          f\"BLEU {val_bleu:.2f} | TF {tf_ratio:.2f} | LR {lr:.5f}\")\n",
    "\n",
    "    improved = False\n",
    "\n",
    "    if val_bleu > best_bleu + 1e-4:\n",
    "        best_bleu = val_bleu\n",
    "        torch.save(model.state_dict(), 'best_beam_bleu.pt')\n",
    "        improved = True\n",
    "        print(\"  → New best BLEU saved\")\n",
    "\n",
    "    if val_loss < best_val_loss - 1e-3:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_beam_loss.pt')\n",
    "        improved = True\n",
    "        print(\"  → New best ValLoss saved\")\n",
    "\n",
    "    if not improved:\n",
    "        no_imp += 1\n",
    "        print(f\"  No improvement for {no_imp}/{PATIENCE} epochs\")\n",
    "        if no_imp >= PATIENCE:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    else:\n",
    "        no_imp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T12:25:33.109861Z",
     "iopub.status.busy": "2025-07-20T12:25:33.109579Z",
     "iopub.status.idle": "2025-07-20T12:25:43.020987Z",
     "shell.execute_reply": "2025-07-20T12:25:43.019874Z",
     "shell.execute_reply.started": "2025-07-20T12:25:33.109839Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final evaluation with full BLEU on validation and test:\n",
      "Validation BLEU (full): 3.40\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Seq2Seq:\n\tMissing key(s) in state_dict: \"enc.gru.weight_ih_l3\", \"enc.gru.weight_hh_l3\", \"enc.gru.bias_ih_l3\", \"enc.gru.bias_hh_l3\", \"enc.gru.weight_ih_l3_reverse\", \"enc.gru.weight_hh_l3_reverse\", \"enc.gru.bias_ih_l3_reverse\", \"enc.gru.bias_hh_l3_reverse\", \"dec.gru.weight_ih_l3\", \"dec.gru.weight_hh_l3\", \"dec.gru.bias_ih_l3\", \"dec.gru.bias_hh_l3\". \n\tsize mismatch for enc.embedding.weight: copying a param with shape torch.Size([16000, 300]) from checkpoint, the shape in current model is torch.Size([16000, 400]).\n\tsize mismatch for enc.gru.weight_ih_l0: copying a param with shape torch.Size([2304, 300]) from checkpoint, the shape in current model is torch.Size([3072, 400]).\n\tsize mismatch for enc.gru.weight_hh_l0: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l0_reverse: copying a param with shape torch.Size([2304, 300]) from checkpoint, the shape in current model is torch.Size([3072, 400]).\n\tsize mismatch for enc.gru.weight_hh_l0_reverse: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l0_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l0_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l1: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l1: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l1_reverse: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l1_reverse: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l1_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l1_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l2: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l2: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l2_reverse: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l2_reverse: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l2_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l2_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.fc.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for enc.fc.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for dec.emb.weight: copying a param with shape torch.Size([16000, 300]) from checkpoint, the shape in current model is torch.Size([16000, 400]).\n\tsize mismatch for dec.attn.attn.weight: copying a param with shape torch.Size([768, 2304]) from checkpoint, the shape in current model is torch.Size([1024, 3072]).\n\tsize mismatch for dec.attn.attn.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for dec.attn.v.weight: copying a param with shape torch.Size([1, 768]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for dec.gru.weight_ih_l0: copying a param with shape torch.Size([2304, 1836]) from checkpoint, the shape in current model is torch.Size([3072, 2448]).\n\tsize mismatch for dec.gru.weight_hh_l0: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.bias_ih_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.bias_hh_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.weight_ih_l1: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.weight_hh_l1: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.bias_ih_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.bias_hh_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.weight_ih_l2: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.weight_hh_l2: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.bias_ih_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.bias_hh_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.fc.weight: copying a param with shape torch.Size([16000, 2604]) from checkpoint, the shape in current model is torch.Size([16000, 3472]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/3481126558.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation BLEU (full): {val_full_bleu:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_beam.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tMissing key(s) in state_dict: \"enc.gru.weight_ih_l3\", \"enc.gru.weight_hh_l3\", \"enc.gru.bias_ih_l3\", \"enc.gru.bias_hh_l3\", \"enc.gru.weight_ih_l3_reverse\", \"enc.gru.weight_hh_l3_reverse\", \"enc.gru.bias_ih_l3_reverse\", \"enc.gru.bias_hh_l3_reverse\", \"dec.gru.weight_ih_l3\", \"dec.gru.weight_hh_l3\", \"dec.gru.bias_ih_l3\", \"dec.gru.bias_hh_l3\". \n\tsize mismatch for enc.embedding.weight: copying a param with shape torch.Size([16000, 300]) from checkpoint, the shape in current model is torch.Size([16000, 400]).\n\tsize mismatch for enc.gru.weight_ih_l0: copying a param with shape torch.Size([2304, 300]) from checkpoint, the shape in current model is torch.Size([3072, 400]).\n\tsize mismatch for enc.gru.weight_hh_l0: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l0_reverse: copying a param with shape torch.Size([2304, 300]) from checkpoint, the shape in current model is torch.Size([3072, 400]).\n\tsize mismatch for enc.gru.weight_hh_l0_reverse: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l0_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l0_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l1: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l1: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l1_reverse: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l1_reverse: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l1_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l1_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l2: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l2: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.weight_ih_l2_reverse: copying a param with shape torch.Size([2304, 1536]) from checkpoint, the shape in current model is torch.Size([3072, 2048]).\n\tsize mismatch for enc.gru.weight_hh_l2_reverse: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for enc.gru.bias_ih_l2_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.gru.bias_hh_l2_reverse: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for enc.fc.weight: copying a param with shape torch.Size([768, 1536]) from checkpoint, the shape in current model is torch.Size([1024, 2048]).\n\tsize mismatch for enc.fc.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for dec.emb.weight: copying a param with shape torch.Size([16000, 300]) from checkpoint, the shape in current model is torch.Size([16000, 400]).\n\tsize mismatch for dec.attn.attn.weight: copying a param with shape torch.Size([768, 2304]) from checkpoint, the shape in current model is torch.Size([1024, 3072]).\n\tsize mismatch for dec.attn.attn.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for dec.attn.v.weight: copying a param with shape torch.Size([1, 768]) from checkpoint, the shape in current model is torch.Size([1, 1024]).\n\tsize mismatch for dec.gru.weight_ih_l0: copying a param with shape torch.Size([2304, 1836]) from checkpoint, the shape in current model is torch.Size([3072, 2448]).\n\tsize mismatch for dec.gru.weight_hh_l0: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.bias_ih_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.bias_hh_l0: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.weight_ih_l1: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.weight_hh_l1: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.bias_ih_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.bias_hh_l1: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.weight_ih_l2: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.weight_hh_l2: copying a param with shape torch.Size([2304, 768]) from checkpoint, the shape in current model is torch.Size([3072, 1024]).\n\tsize mismatch for dec.gru.bias_ih_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.gru.bias_hh_l2: copying a param with shape torch.Size([2304]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for dec.fc.weight: copying a param with shape torch.Size([16000, 2604]) from checkpoint, the shape in current model is torch.Size([16000, 3472])."
     ]
    }
   ],
   "source": [
    "#  8. FULL EVAL AFTER TRAINING \n",
    "print(\"\\nFinal evaluation with full BLEU on validation and test:\")\n",
    "\n",
    "val_full_bleu = calc_bleu(quick=False)\n",
    "print(f\"Validation BLEU (full): {val_full_bleu:.2f}\")\n",
    "\n",
    "model.load_state_dict(torch.load('best_beam.pt'))\n",
    "refs,hyps=[],[]\n",
    "with torch.no_grad():\n",
    "    for i,(src,trg) in enumerate(test_loader):\n",
    "        if i >= 10: break\n",
    "        src,trg=src.to(device),trg.to(device)\n",
    "        for j in range(min(src.size(0),5)):\n",
    "            ps = beam_search(src[j:j+1],k=5,max_len=trg.size(1))\n",
    "            hyps.append(sp.DecodeIds(ps).split())\n",
    "            r = trg[j].tolist()\n",
    "            if EOS in r: r = r[1:r.index(EOS)]\n",
    "            refs.append([sp.DecodeIds(r).split()])\n",
    "test_bleu = corpus_bleu(refs,hyps,smoothing_function=smooth) * 100\n",
    "print(f\"Test BLEU: {test_bleu:.2f}\")\n",
    "\n",
    "print(\"\\nSample translations:\")\n",
    "for _ in range(3):\n",
    "    idx = random.randrange(len(test_df))\n",
    "    s = test_df.iloc[idx]['asm']; r = test_df.iloc[idx]['eng']\n",
    "    ids = [SOS] + sp.EncodeAsIds(s.lower()) + [EOS]\n",
    "    ps = beam_search(torch.tensor([ids],device=device),k=5,max_len=len(ids))\n",
    "    print(\"SRC:\", s)\n",
    "    print(\"REF:\", r)\n",
    "    print(\"PRED:\", sp.DecodeIds(ps))\n",
    "    print(\"-\"*50)\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T13:08:33.764109Z",
     "iopub.status.busy": "2025-07-20T13:08:33.763401Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Loading Data and Training Tokenizer ---\n",
      "Data split: 5536 training, 616 validation, 1538 test pairs.\n",
      "Joint Vocabulary Size: 8000\n",
      "\n",
      "--- Sample Vocabulary Tokens ---\n",
      "Sample tokens: ['▁t', 'he', '▁a', 'in', '▁the', '▁ক', 'য়', 'াৰ', '▁ব', '▁প', '▁s', '▁o', '▁স', 're', '্ৰ', '▁b', 'er', 'ha', '▁c', 'en', 'on']\n",
      "\n",
      "DataLoaders created with batch size 64.\n",
      "\n",
      "--- Initializing Tuned Model and Training ---\n",
      "Model has 31,173,952 trainable parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⭐️ New best BLEU score: 0.01. Model saved.\n",
      "Epoch: 01 | Time: 69s | Train Loss: 7.517 | Val. Loss: 7.004 | Val. BLEU: 0.01 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.01. Model saved.\n",
      "Epoch: 02 | Time: 69s | Train Loss: 6.989 | Val. Loss: 6.977 | Val. BLEU: 0.01 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.01. Model saved.\n",
      "Epoch: 03 | Time: 69s | Train Loss: 6.932 | Val. Loss: 6.962 | Val. BLEU: 0.01 | Patience: 0/7\n",
      "Epoch: 04 | Time: 68s | Train Loss: 6.877 | Val. Loss: 6.959 | Val. BLEU: 0.01 | Patience: 1/7\n",
      "Epoch: 05 | Time: 68s | Train Loss: 6.824 | Val. Loss: 6.932 | Val. BLEU: 0.01 | Patience: 2/7\n",
      "⭐️ New best BLEU score: 0.02. Model saved.\n",
      "Epoch: 06 | Time: 69s | Train Loss: 6.779 | Val. Loss: 6.932 | Val. BLEU: 0.02 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.02. Model saved.\n",
      "Epoch: 07 | Time: 70s | Train Loss: 6.735 | Val. Loss: 6.994 | Val. BLEU: 0.02 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.28. Model saved.\n",
      "Epoch: 08 | Time: 69s | Train Loss: 6.693 | Val. Loss: 6.960 | Val. BLEU: 0.28 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.56. Model saved.\n",
      "Epoch: 09 | Time: 69s | Train Loss: 6.646 | Val. Loss: 6.959 | Val. BLEU: 0.56 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.57. Model saved.\n",
      "Epoch: 10 | Time: 68s | Train Loss: 6.607 | Val. Loss: 6.922 | Val. BLEU: 0.57 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.74. Model saved.\n",
      "Epoch: 11 | Time: 69s | Train Loss: 6.561 | Val. Loss: 6.927 | Val. BLEU: 0.74 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.80. Model saved.\n",
      "Epoch: 12 | Time: 69s | Train Loss: 6.509 | Val. Loss: 6.943 | Val. BLEU: 0.80 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 0.87. Model saved.\n",
      "Epoch: 13 | Time: 68s | Train Loss: 6.465 | Val. Loss: 6.915 | Val. BLEU: 0.87 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.00. Model saved.\n",
      "Epoch: 14 | Time: 69s | Train Loss: 6.419 | Val. Loss: 6.951 | Val. BLEU: 1.00 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.13. Model saved.\n",
      "Epoch: 15 | Time: 68s | Train Loss: 6.376 | Val. Loss: 6.983 | Val. BLEU: 1.13 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.20. Model saved.\n",
      "Epoch: 16 | Time: 68s | Train Loss: 6.332 | Val. Loss: 6.951 | Val. BLEU: 1.20 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.28. Model saved.\n",
      "Epoch: 17 | Time: 69s | Train Loss: 6.288 | Val. Loss: 6.952 | Val. BLEU: 1.28 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.33. Model saved.\n",
      "Epoch: 18 | Time: 70s | Train Loss: 6.245 | Val. Loss: 6.946 | Val. BLEU: 1.33 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.42. Model saved.\n",
      "Epoch: 19 | Time: 68s | Train Loss: 6.212 | Val. Loss: 6.943 | Val. BLEU: 1.42 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.46. Model saved.\n",
      "Epoch: 20 | Time: 69s | Train Loss: 6.167 | Val. Loss: 6.969 | Val. BLEU: 1.46 | Patience: 0/7\n",
      "Epoch: 21 | Time: 69s | Train Loss: 6.128 | Val. Loss: 6.977 | Val. BLEU: 1.40 | Patience: 1/7\n",
      "⭐️ New best BLEU score: 1.58. Model saved.\n",
      "Epoch: 22 | Time: 68s | Train Loss: 6.087 | Val. Loss: 6.969 | Val. BLEU: 1.58 | Patience: 0/7\n",
      "Epoch: 23 | Time: 68s | Train Loss: 6.038 | Val. Loss: 6.970 | Val. BLEU: 1.54 | Patience: 1/7\n",
      "⭐️ New best BLEU score: 1.76. Model saved.\n",
      "Epoch: 24 | Time: 70s | Train Loss: 6.015 | Val. Loss: 6.888 | Val. BLEU: 1.76 | Patience: 0/7\n",
      "Epoch: 25 | Time: 69s | Train Loss: 5.963 | Val. Loss: 6.912 | Val. BLEU: 1.67 | Patience: 1/7\n",
      "⭐️ New best BLEU score: 1.86. Model saved.\n",
      "Epoch: 26 | Time: 68s | Train Loss: 5.926 | Val. Loss: 6.924 | Val. BLEU: 1.86 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 1.90. Model saved.\n",
      "Epoch: 27 | Time: 68s | Train Loss: 5.894 | Val. Loss: 6.930 | Val. BLEU: 1.90 | Patience: 0/7\n",
      "Epoch: 28 | Time: 69s | Train Loss: 5.845 | Val. Loss: 6.943 | Val. BLEU: 1.78 | Patience: 1/7\n",
      "Epoch: 29 | Time: 68s | Train Loss: 5.813 | Val. Loss: 6.971 | Val. BLEU: 1.87 | Patience: 2/7\n",
      "⭐️ New best BLEU score: 2.07. Model saved.\n",
      "Epoch: 30 | Time: 69s | Train Loss: 5.780 | Val. Loss: 6.882 | Val. BLEU: 2.07 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 2.10. Model saved.\n",
      "Epoch: 31 | Time: 68s | Train Loss: 5.724 | Val. Loss: 6.928 | Val. BLEU: 2.10 | Patience: 0/7\n",
      "Epoch: 32 | Time: 69s | Train Loss: 5.706 | Val. Loss: 6.921 | Val. BLEU: 2.07 | Patience: 1/7\n",
      "Epoch: 33 | Time: 68s | Train Loss: 5.645 | Val. Loss: 6.917 | Val. BLEU: 1.96 | Patience: 2/7\n",
      "⭐️ New best BLEU score: 2.10. Model saved.\n",
      "Epoch: 34 | Time: 70s | Train Loss: 5.629 | Val. Loss: 6.921 | Val. BLEU: 2.10 | Patience: 0/7\n",
      "Epoch: 35 | Time: 69s | Train Loss: 5.601 | Val. Loss: 6.847 | Val. BLEU: 2.09 | Patience: 1/7\n",
      "⭐️ New best BLEU score: 2.20. Model saved.\n",
      "Epoch: 36 | Time: 70s | Train Loss: 5.564 | Val. Loss: 6.890 | Val. BLEU: 2.20 | Patience: 0/7\n",
      "Epoch: 37 | Time: 68s | Train Loss: 5.528 | Val. Loss: 6.934 | Val. BLEU: 2.01 | Patience: 1/7\n",
      "Epoch: 38 | Time: 68s | Train Loss: 5.500 | Val. Loss: 6.927 | Val. BLEU: 2.19 | Patience: 2/7\n",
      "Epoch: 39 | Time: 69s | Train Loss: 5.465 | Val. Loss: 6.904 | Val. BLEU: 2.18 | Patience: 3/7\n",
      "⭐️ New best BLEU score: 2.30. Model saved.\n",
      "Epoch: 40 | Time: 70s | Train Loss: 5.391 | Val. Loss: 6.909 | Val. BLEU: 2.30 | Patience: 0/7\n",
      "⭐️ New best BLEU score: 2.33. Model saved.\n",
      "Epoch: 41 | Time: 69s | Train Loss: 5.380 | Val. Loss: 6.952 | Val. BLEU: 2.33 | Patience: 0/7\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# === 1. IMPORTS AND SETUP ===\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "# Set device and ensure reproducibility for consistent results\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==============================================================================\n",
    "# === 2. DATA LOADING & TOKENIZER TUNING ===\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Loading Data and Training Tokenizer ---\")\n",
    "# Fixed data loading and using correct column names\n",
    "df = pd.read_csv('/kaggle/input/filtered/Filtered_data.tsv', sep='\\t',\n",
    "                 on_bad_lines='skip', names=[\"Assamese sentence\", \"English sentence\"])\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=SEED)\n",
    "\n",
    "# NEW: Print the number of sentence pairs in each split\n",
    "print(f\"Data split: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test pairs.\")\n",
    "\n",
    "# Prepare a combined text file for a joint vocabulary\n",
    "with open('all_text_for_bpe.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in pd.concat([train_df['Assamese sentence'], train_df['English sentence']]):\n",
    "        f.write(str(text).strip().lower() + '\\n')\n",
    "\n",
    "# Train a shared BPE model with a tuned vocabulary size\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input=all_text_for_bpe.txt --model_prefix=spm_bpe --vocab_size=8000 '\n",
    "    '--character_coverage=1.0 --model_type=bpe --pad_id=0 --pad_piece=<pad> '\n",
    "    '--bos_id=1 --bos_piece=<s> --eos_id=2 --eos_piece=</s> --unk_id=3 --unk_piece=<unk>'\n",
    ")\n",
    "\n",
    "# Load the trained tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('spm_bpe.model')\n",
    "\n",
    "# Define special token indices\n",
    "PAD_IDX, SOS_IDX, EOS_IDX = sp.pad_id(), sp.bos_id(), sp.eos_id()\n",
    "VOCAB_SIZE = sp.GetPieceSize()\n",
    "print(f\"Joint Vocabulary Size: {VOCAB_SIZE}\")\n",
    "\n",
    "# NEW: Show some sample tokens from the generated vocabulary\n",
    "print(\"\\n--- Sample Vocabulary Tokens ---\")\n",
    "sample_tokens = [sp.IdToPiece(i) for i in range(4, 25)]\n",
    "print(f\"Sample tokens: {sample_tokens}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# === 3. DATASET AND DATALOADERS ===\n",
    "# ==============================================================================\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, df, sp_model, max_len=100):\n",
    "        self.src_sents = df['Assamese sentence'].astype(str).tolist()\n",
    "        self.trg_sents = df['English sentence'].astype(str).tolist()\n",
    "        self.sp_model = sp_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_encoded = self.sp_model.EncodeAsIds(self.src_sents[idx].lower().strip())\n",
    "        trg_encoded = self.sp_model.EncodeAsIds(self.trg_sents[idx].lower().strip())\n",
    "        src_tensor = torch.LongTensor([SOS_IDX] + src_encoded[:self.max_len-2] + [EOS_IDX])\n",
    "        trg_tensor = torch.LongTensor([SOS_IDX] + trg_encoded[:self.max_len-2] + [EOS_IDX])\n",
    "        return src_tensor, trg_tensor\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs, trgs = zip(*batch)\n",
    "    src_padded = pad_sequence(srcs, batch_first=True, padding_value=PAD_IDX)\n",
    "    trg_padded = pad_sequence(trgs, batch_first=True, padding_value=PAD_IDX)\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(TranslationDataset(train_df, sp), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(TranslationDataset(val_df, sp), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(TranslationDataset(test_df, sp), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "print(f\"\\nDataLoaders created with batch size {BATCH_SIZE}.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# === 4. MODEL ARCHITECTURE ===\n",
    "# ==============================================================================\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, num_layers=n_layers,\n",
    "                          bidirectional=True, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_hidden = nn.Linear(hid_dim * 2, hid_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        s = hidden.shape\n",
    "        hidden = hidden.view(self.rnn.num_layers, 2, s[1], s[2])\n",
    "        hidden_cat = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=2)\n",
    "        decoder_hidden = torch.tanh(self.fc_hidden(hidden_cat))\n",
    "        return outputs, decoder_hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((hid_dim * 2) + hid_dim, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        top_hidden = hidden[-1]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        top_hidden = top_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((top_hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
    "        self.rnn = nn.GRU((hid_dim * 2) + emb_dim, hid_dim, num_layers=n_layers,\n",
    "                          dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        self.fc_out = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        a = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
    "        context = torch.bmm(a, encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        output, new_hidden = self.rnn(rnn_input, hidden)\n",
    "        embedded, output, context = embedded.squeeze(1), output.squeeze(1), context.squeeze(1)\n",
    "        prediction = self.fc_out(torch.cat((output, context, embedded), dim=1))\n",
    "        return prediction, new_hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder, self.decoder, self.device = encoder, decoder, device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        input = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "# ==============================================================================\n",
    "# === 5. TRAINING & EVALUATION FUNCTIONS ===\n",
    "# ==============================================================================\n",
    "def train_epoch(model, dataloader, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in dataloader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_refs, all_hyps = [], []\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, 0) # No teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "            loss_output, loss_trg = output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1)\n",
    "            epoch_loss += criterion(loss_output, loss_trg).item()\n",
    "            hyp_tokens = output.argmax(2)\n",
    "            for i in range(hyp_tokens.shape[0]):\n",
    "                hyp_ids, ref_ids = hyp_tokens[i, 1:].tolist(), trg[i, 1:].tolist()\n",
    "                if EOS_IDX in hyp_ids: hyp_ids = hyp_ids[:hyp_ids.index(EOS_IDX)]\n",
    "                if EOS_IDX in ref_ids: ref_ids = ref_ids[:ref_ids.index(EOS_IDX)]\n",
    "                all_hyps.append(sp.decode_ids(hyp_ids).split())\n",
    "                all_refs.append([sp.decode_ids(ref_ids).split()])\n",
    "    bleu = corpus_bleu(all_refs, all_hyps, smoothing_function=smooth_fn)\n",
    "    return epoch_loss / len(dataloader), bleu * 100\n",
    "\n",
    "# ==============================================================================\n",
    "# === 6. TUNED HYPERPARAMETERS, INSTANTIATION & TRAINING ===\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Initializing Tuned Model and Training ---\")\n",
    "# Tuned hyperparameters for the 10k dataset\n",
    "EMB_DIM, HID_DIM = 256, 512\n",
    "ENC_LAYERS, DEC_LAYERS = 2, 2\n",
    "ENC_DROPOUT, DEC_DROPOUT = 0.5, 0.5\n",
    "CLIP, NUM_EPOCHS, PATIENCE = 1.0, 50, 7\n",
    "\n",
    "# Instantiate model\n",
    "attn = Attention(HID_DIM)\n",
    "enc = Encoder(VOCAB_SIZE, EMB_DIM, HID_DIM, ENC_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(VOCAB_SIZE, EMB_DIM, HID_DIM, DEC_LAYERS, DEC_DROPOUT, attn)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters.\")\n",
    "\n",
    "# Optimizer, Loss, and Scheduler with strong regularization\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "best_bleu = -1.0\n",
    "epochs_no_improve = 0\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss, valid_bleu = evaluate(model, val_loader, criterion)\n",
    "    end_time = time.time()\n",
    "\n",
    "    scheduler.step(valid_bleu)\n",
    "    if valid_bleu > best_bleu:\n",
    "        best_bleu = valid_bleu\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "        print(f\" New best BLEU score: {valid_bleu:.2f}. Model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    print(f'Epoch: {epoch:02} | Time: {end_time - start_time:.0f}s | Train Loss: {train_loss:.3f} | '\n",
    "          f'Val. Loss: {valid_loss:.3f} | Val. BLEU: {valid_bleu:.2f} | Patience: {epochs_no_improve}/{PATIENCE}')\n",
    "    \n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print('Early stopping triggered!')\n",
    "        break\n",
    "print(f\"\\nTraining finished. Best validation BLEU: {best_bleu:.2f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# === 7. INFERENCE AND FINAL TESTING ===\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Loading Best Model and Testing Translations ---\")\n",
    "# Load the best performing model\n",
    "model.load_state_dict(torch.load('best-model.pt'))\n",
    "\n",
    "def translate_sentence(sentence, model):\n",
    "    model.eval()\n",
    "    tokens = [SOS_IDX] + sp.encode_as_ids(sentence.lower().strip()) + [EOS_IDX]\n",
    "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "    trg_indexes = [SOS_IDX]\n",
    "    for i in range(100):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == EOS_IDX: break\n",
    "    return sp.decode(trg_indexes).strip()\n",
    "\n",
    "# Test on some examples\n",
    "sample_sentences = [\n",
    "    \"তেওঁ আজি বিদ্যালয়লৈ গ'ল।\",\n",
    "    \"বইখন টেবুলৰ ওপৰত আছে।\",\n",
    "    \"মই তোমাক ভাল পাওঁ।\"\n",
    "]\n",
    "for sentence in sample_sentences:\n",
    "    translation = translate_sentence(sentence, model)\n",
    "    print(f\"Source:      {sentence}\")\n",
    "    print(f\"Translation: {translation}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "test_loss, test_bleu = evaluate(model, test_loader, criterion)\n",
    "print(f'\\n Final Test BLEU on unseen data: {test_bleu:.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7899726,
     "sourceId": 12515353,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7905277,
     "sourceId": 12523549,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
