{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T13:08:33.764109Z",
     "iopub.status.busy": "2025-07-20T13:08:33.763401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  1. IMPORTS AND SETUP \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "#  2. DATA LOADING & TOKENIZER TUNING \n",
    "print(\"\\n--- Loading Data and Training Tokenizer ---\")\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/filtered/Filtered_data.tsv', sep='\\t',\n",
    "                 on_bad_lines='skip', names=[\"Assamese sentence\", \"English sentence\"])\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=SEED)\n",
    "\n",
    "\n",
    "print(f\"Data split: {len(train_df)} training, {len(val_df)} validation, {len(test_df)} test pairs.\")\n",
    "\n",
    "\n",
    "with open('all_text_for_bpe.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in pd.concat([train_df['Assamese sentence'], train_df['English sentence']]):\n",
    "        f.write(str(text).strip().lower() + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input=all_text_for_bpe.txt --model_prefix=spm_bpe --vocab_size=8000 '\n",
    "    '--character_coverage=1.0 --model_type=bpe --pad_id=0 --pad_piece=<pad> '\n",
    "    '--bos_id=1 --bos_piece=<s> --eos_id=2 --eos_piece=</s> --unk_id=3 --unk_piece=<unk>'\n",
    ")\n",
    "\n",
    "# Load the trained tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('spm_bpe.model')\n",
    "\n",
    "# Define special token indices\n",
    "PAD_IDX, SOS_IDX, EOS_IDX = sp.pad_id(), sp.bos_id(), sp.eos_id()\n",
    "VOCAB_SIZE = sp.GetPieceSize()\n",
    "print(f\"Joint Vocabulary Size: {VOCAB_SIZE}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Sample Vocabulary Tokens ---\")\n",
    "sample_tokens = [sp.IdToPiece(i) for i in range(4, 25)]\n",
    "print(f\"Sample tokens: {sample_tokens}\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. DATASET AND DATALOADERS \n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, df, sp_model, max_len=100):\n",
    "        self.src_sents = df['Assamese sentence'].astype(str).tolist()\n",
    "        self.trg_sents = df['English sentence'].astype(str).tolist()\n",
    "        self.sp_model = sp_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_encoded = self.sp_model.EncodeAsIds(self.src_sents[idx].lower().strip())\n",
    "        trg_encoded = self.sp_model.EncodeAsIds(self.trg_sents[idx].lower().strip())\n",
    "        src_tensor = torch.LongTensor([SOS_IDX] + src_encoded[:self.max_len-2] + [EOS_IDX])\n",
    "        trg_tensor = torch.LongTensor([SOS_IDX] + trg_encoded[:self.max_len-2] + [EOS_IDX])\n",
    "        return src_tensor, trg_tensor\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs, trgs = zip(*batch)\n",
    "    src_padded = pad_sequence(srcs, batch_first=True, padding_value=PAD_IDX)\n",
    "    trg_padded = pad_sequence(trgs, batch_first=True, padding_value=PAD_IDX)\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(TranslationDataset(train_df, sp), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(TranslationDataset(val_df, sp), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(TranslationDataset(test_df, sp), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "print(f\"\\nDataLoaders created with batch size {BATCH_SIZE}.\")\n",
    "\n",
    "#  4. MODEL ARCHITECTURE \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, num_layers=n_layers,\n",
    "                          bidirectional=True, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_hidden = nn.Linear(hid_dim * 2, hid_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        s = hidden.shape\n",
    "        hidden = hidden.view(self.rnn.num_layers, 2, s[1], s[2])\n",
    "        hidden_cat = torch.cat((hidden[:, 0, :, :], hidden[:, 1, :, :]), dim=2)\n",
    "        decoder_hidden = torch.tanh(self.fc_hidden(hidden_cat))\n",
    "        return outputs, decoder_hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((hid_dim * 2) + hid_dim, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        top_hidden = hidden[-1]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        top_hidden = top_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((top_hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, n_layers, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=PAD_IDX)\n",
    "        self.rnn = nn.GRU((hid_dim * 2) + emb_dim, hid_dim, num_layers=n_layers,\n",
    "                          dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        self.fc_out = nn.Linear((hid_dim * 2) + hid_dim + emb_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        a = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
    "        context = torch.bmm(a, encoder_outputs)\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "        output, new_hidden = self.rnn(rnn_input, hidden)\n",
    "        embedded, output, context = embedded.squeeze(1), output.squeeze(1), context.squeeze(1)\n",
    "        prediction = self.fc_out(torch.cat((output, context, embedded), dim=1))\n",
    "        return prediction, new_hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder, self.decoder, self.device = encoder, decoder, device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size, trg_len = trg.shape\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        input = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "\n",
    "#  5. TRAINING & EVALUATION FUNCTIONS \n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg in dataloader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_refs, all_hyps = [], []\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            output = model(src, trg, 0) # No teacher forcing\n",
    "            output_dim = output.shape[-1]\n",
    "            loss_output, loss_trg = output[:, 1:].reshape(-1, output_dim), trg[:, 1:].reshape(-1)\n",
    "            epoch_loss += criterion(loss_output, loss_trg).item()\n",
    "            hyp_tokens = output.argmax(2)\n",
    "            for i in range(hyp_tokens.shape[0]):\n",
    "                hyp_ids, ref_ids = hyp_tokens[i, 1:].tolist(), trg[i, 1:].tolist()\n",
    "                if EOS_IDX in hyp_ids: hyp_ids = hyp_ids[:hyp_ids.index(EOS_IDX)]\n",
    "                if EOS_IDX in ref_ids: ref_ids = ref_ids[:ref_ids.index(EOS_IDX)]\n",
    "                all_hyps.append(sp.decode_ids(hyp_ids).split())\n",
    "                all_refs.append([sp.decode_ids(ref_ids).split()])\n",
    "    bleu = corpus_bleu(all_refs, all_hyps, smoothing_function=smooth_fn)\n",
    "    return epoch_loss / len(dataloader), bleu * 100\n",
    "\n",
    "\n",
    "#  6. TUNED HYPERPARAMETERS, INSTANTIATION & TRAINING \n",
    "\n",
    "print(\"\\n--- Initializing Tuned Model and Training ---\")\n",
    "\n",
    "EMB_DIM, HID_DIM = 256, 512\n",
    "ENC_LAYERS, DEC_LAYERS = 2, 2\n",
    "ENC_DROPOUT, DEC_DROPOUT = 0.5, 0.5\n",
    "CLIP, NUM_EPOCHS, PATIENCE = 1.0, 50, 7\n",
    "\n",
    "# Instantiate model\n",
    "attn = Attention(HID_DIM)\n",
    "enc = Encoder(VOCAB_SIZE, EMB_DIM, HID_DIM, ENC_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(VOCAB_SIZE, EMB_DIM, HID_DIM, DEC_LAYERS, DEC_DROPOUT, attn)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters.\")\n",
    "\n",
    "# Optimizer, Loss, and Scheduler with strong regularization\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "best_bleu = -1.0\n",
    "epochs_no_improve = 0\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss, valid_bleu = evaluate(model, val_loader, criterion)\n",
    "    end_time = time.time()\n",
    "\n",
    "    scheduler.step(valid_bleu)\n",
    "    if valid_bleu > best_bleu:\n",
    "        best_bleu = valid_bleu\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "        print(f\" New best BLEU score: {valid_bleu:.2f}. Model saved.\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    print(f'Epoch: {epoch:02} | Time: {end_time - start_time:.0f}s | Train Loss: {train_loss:.3f} | '\n",
    "          f'Val. Loss: {valid_loss:.3f} | Val. BLEU: {valid_bleu:.2f} | Patience: {epochs_no_improve}/{PATIENCE}')\n",
    "    \n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print('Early stopping triggered!')\n",
    "        break\n",
    "print(f\"\\nTraining finished. Best validation BLEU: {best_bleu:.2f}\")\n",
    "\n",
    "#  7. INFERENCE AND FINAL TESTING \n",
    "print(\"\\n--- Loading Best Model and Testing Translations ---\")\n",
    "# Load the best performing model\n",
    "model.load_state_dict(torch.load('best-model.pt'))\n",
    "\n",
    "def translate_sentence(sentence, model):\n",
    "    model.eval()\n",
    "    tokens = [SOS_IDX] + sp.encode_as_ids(sentence.lower().strip()) + [EOS_IDX]\n",
    "    src_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
    "    trg_indexes = [SOS_IDX]\n",
    "    for i in range(100):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == EOS_IDX: break\n",
    "    return sp.decode(trg_indexes).strip()\n",
    "\n",
    "# Test on some examples\n",
    "sample_sentences = [\n",
    "    \"তেওঁ আজি বিদ্যালয়লৈ গ'ল।\",\n",
    "    \"বইখন টেবুলৰ ওপৰত আছে।\",\n",
    "    \"মই তোমাক ভাল পাওঁ।\"\n",
    "]\n",
    "for sentence in sample_sentences:\n",
    "    translation = translate_sentence(sentence, model)\n",
    "    print(f\"Source:      {sentence}\")\n",
    "    print(f\"Translation: {translation}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "test_loss, test_bleu = evaluate(model, test_loader, criterion)\n",
    "print(f'\\n Final Test BLEU on unseen data: {test_bleu:.2f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7899726,
     "sourceId": 12515353,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7905277,
     "sourceId": 12523549,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
